[
  {
    "id": "0001",
    "title": "以下代码有问题吗，是什么问题？",
    "content": "1.1\nList<Object> obj = new ArrayList<Long>();\nobj.add(\"I love Android!\");\n\n1.2\nObject[] objArray = new Long[1];\nobjArray[0] = \"I love Android!\";",
    "answer": "结果：</br>1.1 编译出错。</br>1.2 编译可以，运行出错。</br></br>原因：</br>1.1 List\\<Object\\>和ArrayList\\<Long\\>没有继承关系。</br>1.2 数组是在运行时类型检查。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0002",
    "title": "以下代码有问题吗，是什么问题？",
    "content": "2.1\nLong l1 = 128L;\nLong l2 = 128L;\nSystem.out.print(l1 == l2);\nSystem.out.print(l1 == 128L);\n\n2.2\nLong l1 = 127L;\nLong l2 = 127L;\nSystem.out.print(l1 == l2);\nSystem.out.print(l1 == 127L);",
    "answer": "结果：</br>2.1 false  true。   </br>2.2 true  true。</br></br>原因：</br></br>2.1 Long 包装类型常量 cache 为 -128 ～ 127 之间，所以 l1 和 l2 是两个对象，== 比较的是对象的地址，所以第一个打印为 false；接着由于包装类型在表达式中且表达式中至少有一个不是包装类型，所以 Long l1== 128L 中 l1 自动拆箱比较，所以数值比较为 true。</br></br>2.2 Long 包装类型 -128 - 127 之间的值 Java 维护在一个常量池中，所以 l1 和 l2 引用同一个对象。</br></br>还可参见第 16 题解析。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0003",
    "title": "内部类你知多少？",
    "content": "java 内部类分为几种，各种自己有哪些特性？",
    "answer": "静态内部类，成员内部类，方法内部类，匿名内部类；</br></br>匿名内部类访问外部类的局部变量，局部变量需要 final 修饰，1.8 之后该关键字被省略。</br></br>方法内部类只能在定义该内部类的方法内实例化，不可以在此方法外对其实例化。</br></br>静态内部类与其他成员相似，可以用 static 修饰内部类，这样的类称为静态内部类，静态内部类与静态内部方法相似，只能访问外部类的 static 成员，不能直接访问外部类的实例变量，与实例方法，只有通过对象引用才能访问。</br></br>成员内部类没有用 static 修饰且定义在在外部类类体中。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0004",
    "title": "什么是泛型中的限定通配符和非限定通配符？",
    "content": "无",
    "answer": "解答：</br></br>限定通配符对类型进行了限制，有两种限定通配符，一种是<? extends T>通过确保类型必须是 T 的子类来设定类型的上界，另一种是<? super T>它通过确保类型必须是 T 的父类来设定类型的下界，泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。 另一方面<?>表示非限定通配符，因为<?>可以用任意类型来替代。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0005",
    "title": "简单说说 Java 中List<Object>和原始类型List之间的区别？",
    "content": "无",
    "answer": "解答：</br></br>区别一：原始类型和带泛型参数类型<Object>之间的主要区别是在编译时编译器不会对原始类型进行类型安全检查，却会对带参数的类型进行检查，通过使用 Object 作为类型可以告知编译器该方法可以接受任何类型的对象（比如 String 或 Integer）。</br></br>区别二：我们可以把任何带参数的类型传递给原始类型 List，但却不能把List<String>传递给接受List<Object>的方法，因为会产生编译错误。</br></br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0006",
    "title": "Java 中List<?>和List<Object>之间的区别是什么？",
    "content": "无",
    "answer": "解答：</br></br>这道题跟上一道题看起来很像，实质上却完全不同。List<?>是一个未知类型的List，而List<Object>其实是任意类型的List。我们可以把List<String>, List<Integer>赋值给List<?>，却不能把List<String>赋值给List<Object>。譬如：</br></br>List<?> listOfAnyType;</br>List<Object> listOfObject = new ArrayList<Object>();</br>List<String> listOfString = new ArrayList<String>();</br>List<Integer> listOfInteger = new ArrayList<Integer>();</br>listOfAnyType = listOfString; //legal</br>listOfAnyType = listOfInteger; //legal</br>listOfObjectType = (List<Object>) listOfString; //compiler error – in-convertible types</br>所以通配符形式都可以用类型参数的形式来替代，通配符能做的用类型参数都能做。 通配符形式可以减少类型参数，形式上往往更为简单，可读性也更好，所以能用通配符的就用通配符。 如果类型参数之间有依赖关系或者返回值依赖类型参数或者需要写操作则只能用类型参数。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0007",
    "title": "List<? extends T>和List <? super T>之间有什么区别？",
    "content": "无",
    "answer": "解答：</br></br>有时面试官会用这个问题来评估你对泛型的理解，而不是直接问你什么是限定通配符和非限定通配符，这两个List的声明都是限定通配符的例子，List<? extends T>可以接受任何继承自 T 的类型的List，而List<? super T>可以接受任何 T 的父类构成的List。 例如List<? extends Number>可以接受List<Integer>或List<Float>。Java 容器类的实现中有很多这种用法，比如 Collections 中就有如下一些方法：</br></br>public static <T extends Comparable<? super T>> void sort(List<T> list)</br>public static <T> void sort(List<T> list, Comparator<? super T> c)</br>public static <T> void copy(List<? super T> dest, List<? extends T> src)</br>public static <T> T max(Collection<? extends T> coll, Comparator<? super T> comp)",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0008",
    "title": "<T extends E>和<? extends E>有什么关系？",
    "content": "无",
    "answer": "解答：</br></br>它们用的地方不一样，<T extends E>用于定义类型参数，声明了一个类型参数 T，可放在泛型类定义中类名后面、泛型方法返回值前面。 <? extends E>用于实例化类型参数，用于实例化泛型变量中的类型参数，只是这个具体类型是未知的，只知道它是 E 或 E 的某个子类型。 虽然它们不一样，但两种写法经常可以达到相同的目的，譬如：</br></br>public void addAll(Bean<? extends E> c)</br>public <T extends E> void addAll(Bean<T> c) ",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0009",
    "title": "解释下面程序执行情况和原因？",
    "content": "DynamicArray<Integer> ints = new DynamicArray<>();\nDynamicArray<? extends Number> numbers = ints; \nInteger a = 200;\nnumbers.add(a);\t\t//这三行add现象？\nnumbers.add((Number)a);\nnumbers.add((Object)a);\n\npublic void copyTo(DynamicArray<? super E> dest){\n    for(int i=0; i<size; i++){\n        dest.add(get(i));\t//这行add现象？\n    }\n}",
    "answer": "解析：</br></br>上面三种 add 方法都是非法的，无论是 Integer，还是 Number 或 Object，编译器都会报错。因为?表示类型安全无知，? extends Number表示是Number的某个子类型，但不知道具体子类型， 如果允许写入，Java 就无法确保类型安全性，所以直接禁止。</br></br>最后方法的 add 是合法的，因为<? super E>形式与<? extends E>正好相反，超类型通配符表示 E 的某个父类型，有了它我们就可以更灵活的写入了。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00010",
    "title": "Arraylist 的动态扩容机制是如何自动增加的？简单说说你理解的增加流程！",
    "content": "无",
    "answer": "解析：</br></br>当在 ArrayList 中增加一个对象时 Java 会去检查 Arraylist 以确保已存在的数组中有足够的容量来存储这个新对象，如果没有足够容量就新建一个长度更长的数组（原来的1.5倍），旧的数组就会使用 Arrays.copyOf 方法被复制到新的数组中去，现有的数组引用指向了新的数组。下面代码展示为 Java 1.8 中通过 ArrayList.add 方法添加元素时，内部会自动扩容，扩容流程如下：</br></br>//确保容量够用，内部会尝试扩容，如果需要</br>ensureCapacityInternal(size + 1)</br></br>//在未指定容量的情况下，容量为DEFAULT_CAPACITY = 10</br>//并且在第一次使用时创建容器数组，在存储过一次数据后，数组的真实容量至少DEFAULT_CAPACITY</br> private void ensureCapacityInternal(int minCapacity) {</br>    //判断当前的元素容器是否是初始的空数组</br>    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {</br>        //如果是默认的空数组，则 minCapacity 至少为DEFAULT_CAPACITY</br>        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);</br>    }</br></br>    ensureExplicitCapacity(minCapacity);</br>}</br></br>//通过该方法进行真实准确扩容尝试的操作</br> private void ensureExplicitCapacity(int minCapacity) {</br>        modCount++;//记录List的结构修改的次数</br></br>        //需要扩容</br>        if (minCapacity - elementData.length > 0)</br>            grow(minCapacity);</br>}</br></br>//扩容操作</br> private void grow(int minCapacity) {</br>    //原来的容量</br>    int oldCapacity = elementData.length;</br>    </br>    //新的容量 = 原来的容量 + （原来的容量的一半）</br>    int newCapacity = oldCapacity + (oldCapacity >> 1);</br>    </br>    //如果计算的新的容量比指定的扩容容量小，那么就使用指定的容量</br>    if (newCapacity - minCapacity < 0)</br>        newCapacity = minCapacity;</br>    </br>    //如果新的容量大于MAX_ARRAY_SIZE(Integer.MAX_VALUE - 8)</br>    //那么就使用hugeCapacity进行容量分配</br>    if (newCapacity - MAX_ARRAY_SIZE > 0)</br>        newCapacity = (minCapacity > MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;</br>    </br>    //创建长度为newCapacity的数组，并复制原来的元素到新的容器，完成ArrayList的内部扩容</br>    elementData = Arrays.copyOf(elementData, newCapacity);</br> }</br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00011",
    "title": "下面这些方法可以正常运行吗？为什么？",
    "content": "public void remove1(ArrayList<Integer> list) {\n    for(Integer a : list){\n        if(a <= 10){\n            list.remove(a);\n        }\n    }\n}\n\npublic static void remove2(ArrayList<Integer> list) {\n    Iterator<Integer> it = list.iterator();\n    while(it.hasNext()){\n        if(it.next() <= 10) {\n            it.remove();\n        }\n    }\n}\n\npublic static void remove3(ArrayList<Integer> list) {\n    Iterator<Integer> it = list.iterator();\n    while(it.hasNext()) {\n        it.remove();    \n    }\n}\n\npublic static void remove4(ArrayList<Integer> list) {\n    Iterator<Integer> it = list.iterator();\n    while(it.hasNext()) {\n        it.next();\n        it.remove();\n        it.remove();\n    }\n}",
    "answer": "解析：</br></br>remove1 方法会抛出 ConcurrentModificationException 异常，这是迭代器的一个陷阱，foreach 遍历编译后实质会替换为迭代器实现（普通for循环不会抛这个异常，因为list.size方法一般不会变，所以只会漏删除），因为迭代器内部会维护一些索引位置数据，要求在迭代过程中容器不能发生结构性变化（添加、插入、删除，修改数据不算），否则这些索引位置数据就失效了，避免的方式就是使用迭代器的 remove 方法。</br></br>remove2 方法可以正常运行，无任何错误。</br></br>remove3 方法会抛出 IllegalStateException 异常，因为使用迭代器的 remove 方法前必须先调用 next 方法，next 方法会检测容器是否发生了结构性变化，然后更新 cursor 和 lastRet 值，直接不调用 next 而 remove 会导致相关值不正确。</br></br>remove4 方法会抛出 IllegalStateException 异常，理由同 remove3，remove 调用一次后 lastRet 值会重置为 -1，没有调用 next 去设置 lastRet 的情况下再直接调一次 remove 自然就状态异常了。</br></br>当然了，上面四个写法的具体官方解答可参见 ArrayList 中迭代器部分源码，如下：</br></br>private class Itr implements Iterator<E> {</br>\tint cursor;       // index of next element to return</br>\tint lastRet = -1; // index of last element returned; -1 if no such</br>\tint expectedModCount = modCount;</br></br>\tpublic boolean hasNext() {</br>\t\treturn cursor != size;</br>\t}</br></br>\t@SuppressWarnings(\"unchecked\")</br>\tpublic E next() {</br>\t\tcheckForComodification();</br>\t\tint i = cursor;</br>\t\tif (i >= size)</br>\t\t\tthrow new NoSuchElementException();</br>\t\tObject[] elementData = ArrayList.this.elementData;</br>\t\tif (i >= elementData.length)</br>\t\t\tthrow new ConcurrentModificationException();</br>\t\tcursor = i + 1;</br>\t\treturn (E) elementData[lastRet = i];</br>\t}</br></br>\tpublic void remove() {</br>\t\tif (lastRet < 0)</br>\t\t\tthrow new IllegalStateException();</br>\t\tcheckForComodification();</br></br>\t\ttry {</br>\t\t\tArrayList.this.remove(lastRet);</br>\t\t\tcursor = lastRet;</br>\t\t\tlastRet = -1;</br>\t\t\texpectedModCount = modCount;</br>\t\t} catch (IndexOutOfBoundsException ex) {</br>\t\t\tthrow new ConcurrentModificationException();</br>\t\t}</br>\t}</br></br>\tfinal void checkForComodification() {</br>\t\tif (modCount != expectedModCount)</br>\t\t\tthrow new ConcurrentModificationException();</br>\t}</br>}",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00012",
    "title": "简单解释一下 Collection 和 Collections 的区别？",
    "content": "无",
    "answer": "解析：</br></br>java.util.Collection 是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法，在 Java 类库中有很多具体的实现，意义是为各种具体的集合提供最大化的统一操作方式。 譬如 Collection 的实现类有 List、Set 等，List 的实现类有 LinkedList、ArrayList、Vector 等，Vector 的实现类有 Stack 等，不过切记 Map 是自立门户的，其提供了转换为 Collection 的方法，但是自己不是 Collection 的子类。</br></br>java.util.Collections 是一个包装类，它包含有各种有关集合操作的静态多态方法，此类构造 private 不能实例化，就像一个工具类，服务于 Java 的 Collection 框架，其提供的方法大概可以分为对容器接口对象进行操作类（查找和替换、排序和调整顺序、添加和修改）和返回一个容器接口对象类（适配器将其他类型的数据转换为容器接口对象、装饰器修饰一个给定容器接口对象增加某种性质）。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00013",
    "title": "解释一下 ArrayList、Vector、Stack、LinkedList 的实现和区别及特点和适用场景？",
    "content": "无",
    "answer": "解析：</br></br>首先他们都是 List 家族的儿子，List 又是 Collection 的子接口，Collection 又是 Iterable 的子接口，所以他们都具备 Iterable 和 Collection 和 List 的基本特性。</br></br>ArrayList 是一个动态数组队列，随机访问效率高，随机插入、删除效率低。LinkedList 是一个双向链表，它也可以被当作堆栈、队列或双端队列进行操作，随机访问效率低，但随机插入、随机删除效率略好。Vector 是矢量队列，和 ArrayList 一样是一个动态数组，但是 Vector 是线程安全的。Stack 继承于 Vector，特性是先进后出(FILO, FirstIn Last Out)。</br></br>从线程安全角度看 Vector、Stack 是线程安全的，ArrayList、LinkedList 是非线程安全的。</br></br>从实现角度看 LinkedList 是双向链表结构，ArrayList、Vector、Stack 是内存数组结构。</br></br>从动态扩容角度看由于 ArrayList 和 Vector（Stack 继承自 Vector，只在 Vector 的基础上添加了几个 Stack 相关的方法，故之后不再对 Stack 做特别的说明）使用数组实现，当数组长度不够时，其内部会创建一个更大的数组，然后将原数组中的数据拷贝至新数组中，而 LinkedList 是双向链表结构，内存不用连续，所以用多少申请多少。</br></br>从效率方面来说 Vector、ArrayList、Stack 是基于数组实现的，是根据索引来访问元素，Vector（Stack）和 ArrayList 最大的区别就是 synchronization 同步的使用，抛开两个只在序列化过程中使用的方法不说，没有一个 ArrayList 的方法是同步的，相反，绝大多数 Vector（Stack）的方法法都是直接或者间接的同步的，因此就造成 ArrayList 比 Vector（Stack）更快些，不过在最新的 JVM 中，这两个类的速度差别是很小的，几乎可以忽略不计；而 LinkedList 是双向链表实现，根据索引访问元素时需要遍历寻找，性能略差。所以 ArrayList 适合大量随机访问，LinkList 适合频繁删除插入操作。</br></br>从差异角度看 LinkedList 还具备 Deque 双端队列的特性，其实现了 Deque 接口，Deque 继承自 Queue 队列接口，其实也挺好理解，因为 LinkedList 是的实现是双向链表结构，所以实现队列特性实在是太容易了。</br></br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00014",
    "title": "简单介绍下 List 、Map、Set、Queue 的区别和关系？",
    "content": "无",
    "answer": "解析：</br></br>List、Set、Queue 都继承自 Collection 接口，而 Map 则不是（继承自 Object），所以容器类有两个根接口，分别是 Collection 和 Map，Collection 表示单个元素的集合，Map 表示键值对的集合。</br></br>List 的主要特点就是有序性和元素可空性，他维护了元素的特定顺序，其主要实现类有 ArrayList 和 LinkList。ArrayList 底层由数组实现，允许元素随机访问，但是向 ArrayList 列表中间插入删除元素需要移位复制速度略慢；LinkList 底层由双向链表实现，适合频繁向列表中插入删除元素，随机访问需要遍历所以速度略慢，适合当做堆栈、队列、双向队列使用。</br></br>Set 的主要特性就是唯一性和元素可空性，存入 Set 的每个元素都必须唯一，加入 Set 的元素都必须确保对象的唯一性，Set 不保证维护元素的有序性，其主要实现类有 HashSet、LinkHashSet、TreeSet。HashSet 是为快速查找元素而设计，存入 HashSet 的元素必须定义 hashCode 方法，其实质可以理解为是 HashMap 的包装类，所以 HashSet 的值还具备可 null 性；LinkHashSet 具备 HashSet 的查找速度且通过链表保证了元素的插入顺序（实质为 HashSet 的子类），迭代时是有序的，同理存入 LinkHashSet 的元素必须定义 hashCode 方法；TreeSet 实质是 TreeMap 的包装类，所以 TreeSet 的值不备可 null 性，其保证了元素的有序性，底层为红黑树结构，存入 TreeSet 的元素必须实现 Comparable 接口；不过特别注意 EnumSet 的实现和 EnumMap 没有一点关系。</br></br>Queue 的主要特性就是队列和元素不可空性，其主要的实现类有 LinkedList、PriorityQueue。LinkedList 保证了按照元素的插入顺序进行操作；PriorityQueue 按照优先级进行插入抽取操作，元素可以通过实现 Comparable 接口来保证优先顺序。Deque 是 Queue 的子接口，表示更为通用的双端队列，有明确的在头或尾进行查看、添加和删除的方法，ArrayDeque 基于循环数组实现，效率更高一些。</br></br>Map 自立门户，但是也提供了嫁接到 Collection 相关方法，其主要特性就是维护键值对关联和查找特性，其主要实现类有 HashTab、HashMap、LinkedHashMap、TreeMap。HashTab 类似 HashMap，但是不允许键为 null 和值为 null，比 HashMap 慢，因为为同步操作；HashMap 是基于散列列表的实现，其键和值都可以为 null；LinkedHashMap 类似 HashMap，其键和值都可以为 null，其有序性为插入顺序或者最近最少使用的次序（LRU 算法的核心就是这个），之所以能有序，是因为每个元素还加入到了一个双向链表中；TreeMap 是基于红黑树算法实现的，查看键值对时会被排序，存入的元素必须实现 Comparable 接口，但是不允许键为 null，值可以为 null；如果键为枚举类型可以使用专门的实现类 EnumMap，它使用效率更高的数组实现。</br></br>从数据结构角度看集合的区别有如下：</br></br>动态数组：ArrayList 内部是动态数组，HashMap 内部的链表数组也是动态扩展的，ArrayDeque 和 PriorityQueue 内部也都是动态扩展的数组。</br></br>链表：LinkedList 是用双向链表实现的，HashMap 中映射到同一个链表数组的键值对是通过单向链表链接起来的，LinkedHashMap 中每个元素还加入到了一个双向链表中以维护插入或访问顺序。</br></br>哈希表：HashMap 是用哈希表实现的，HashSet, LinkedHashSet 和 LinkedHashMap 基于 HashMap，内部当然也是哈希表。</br></br>排序二叉树：TreeMap 是用红黑树(基于排序二叉树)实现的，TreeSet 内部使用 TreeMap，当然也是红黑树，红黑树能保持元素的顺序且综合性能很高。</br></br>堆：PriorityQueue 是用堆实现的，堆逻辑上是树，物理上是动态数组，堆可以高效地解决一些其他数据结构难以解决的问题。</br></br>循环数组：ArrayDeque 是用循环数组实现的，通过对头尾变量的维护，实现了高效的队列操作。</br></br>位向量：EnumSet 是用位向量实现的，对于只有两种状态且需要进行集合运算的数据使用位向量进行表示、位运算进行处理，精简且高效。</br></br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00015",
    "title": "简单说说 HashMap 的底层原理？",
    "content": "无",
    "answer": "答案：</br></br>当我们往 HashMap 中 put 元素时，先根据 key 的 hash 值得到这个元素在数组中的位置（即下标），然后把这个元素放到对应的位置中，如果这个元素所在的位子上已经存放有其他元素就在同一个位子上的元素以链表的形式存放，新加入的放在链头，从 HashMap 中 get 元素时先计算 key 的 hashcode，找到数组中对应位置的某一元素，然后通过 key 的 equals 方法在对应位置的链表中找到需要的元素，所以 HashMap 的数据结构是数组和链表的结合。</br></br>解析：</br></br>HashMap 底层是基于哈希表的 Map 接口的非同步实现，实际是一个链表散列数据结构（即数组和链表的结合体）。 首先由于数组存储区间是连续的，占用内存严重，故空间复杂度大，但二分查找时间复杂度小（O(1)），所以寻址容易，插入和删除困难。而链表存储区间离散，占用内存比较宽松，故空间复杂度小，但时间复杂度大（O(N)），所以寻址困难，插入和删除容易。 所以就产生了一种新的数据结构------哈希表，哈希表既满足了数据的查找方便，同时不占用太多的内容空间，使用也十分方便，哈希表有多种不同的实现方法，HashMap 采用的是链表的数组实现方式，具体如下：</br></br>首先 HashMap 里面实现了一个静态内部类 Entry(key、value、next)，HashMap 的基础就是一个 Entry[] 线性数组，Map 的内容都保存在 Entry[] 里面，而 HashMap 用的线性数组却是随机存储的原因如下：</br></br>// 存储时</br>int hash = key.hashCode(); //每个 key 的 hash 是一个固定的 int 值 </br>int index = hash % Entry[].length; </br>Entry[index] = value;</br></br>// 取值时</br>int hash = key.hashCode(); </br>int index = hash % Entry[].length; </br>return Entry[index];</br>当我们通过 put 向 HashMap 添加多个元素时会遇到两个 key 通过hash % Entry[].length计算得到相同 index 的情况，这时具有相同 index 的元素就会被放在线性数组 index 位置，然后其 next 属性指向上个同 index 的 Entry 元素形成链表结构（譬如第一个键值对 A 进来，通过计算其 key 的 hash 得到的 index = 0，记做 Entry[0] = A，接着第二个键值对 B 进来，通过计算其 index 也等于 0，这时候 B.next = A, Entry[0] = B，如果又进来 C 且 index 也等于 0 则 C.next = B, Entry[0] = C）。 当我们通过 get 从 HashMap 获取元素时首先会定位到数组元素，接着再遍历该元素处的链表获取真实元素。 当 key 为 null 时 HashMap 特殊处理总是放在 Entry[] 数组的第一个元素。 HashMap 使用 Key 对象的 hashCode() 和 equals() 方法去决定 key-value 对的索引，当我们试着从 HashMap 中获取值的时候，这些方法也会被用到，所以 equals() 和 hashCode() 的实现应该遵循以下规则： 如果o1.equals(o2)则o1.hashCode() == o2.hashCode()必须为 true，或者如果o1.hashCode() == o2.hashCode()则不意味着o1.equals(o2)会为true。</br></br>关于 HashMap 的 hash 函数算法巧妙之处可以参见本文链接：http://pengranxiang.iteye.com/blog/543893",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00016",
    "title": "简单解释一下 Comparable 和 Comparator 的区别和场景？",
    "content": "无",
    "answer": "解析：</br></br>Comparable 对实现它的每个类的对象进行整体排序，这个接口需要类本身去实现，若一个类实现了 Comparable 接口，实现 Comparable 接口的类的对象的 List 列表(或数组)可以通过 Collections.sort（或 Arrays.sort）进行排序，此外实现 Comparable 接口的类的对象可以用作有序映射(如TreeMap)中的键或有序集合(如TreeSet)中的元素，而不需要指定比较器， 实现 Comparable 接口必须修改自身的类（即在自身类中实现接口中相应的方法），如果我们使用的类无法修改（如SDK中一个没有实现Comparable的类），我们又想排序，就得用到 Comparator 这个接口了（策略模式）。 所以如果你正在编写一个值类，它具有非常明显的内在排序关系，比如按字母顺序、按数值顺序或者按年代顺序，那你就应该坚决考虑实现 Comparable 这个接口， 若一个类实现了 Comparable 接口就意味着该类支持排序，而 Comparator 是比较器，我们若需要控制某个类的次序，可以建立一个该类的比较器来进行排序。 Comparable 比较固定，和一个具体类相绑定，而 Comparator 比较灵活，可以被用于各个需要比较功能的类使用。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00017",
    "title": "简单说说 Iterator 和 ListIterator 的区别？",
    "content": "无",
    "answer": "解析：</br></br>ListIterator 有 add() 方法，可以向 List 中添加对象，而 Iterator 不能。</br></br>ListIterator 和 Iterator 都有 hasNext() 和 next() 方法，可以实现顺序向后遍历，但是 ListIterator 有 hasPrevious() 和 previous() 方法，可以实现逆向（顺序向前）遍历，Iterator 就不可以。</br></br>ListIterator 可以定位当前的索引位置，通过 nextIndex() 和 previousIndex() 可以实现，Iterator 没有此功能。</br></br>都可实现删除对象，但是 ListIterator 可以实现对象的修改，通过 set() 方法可以实现，Iierator 仅能遍历，不能修改。</br></br>容器类提供的迭代器都会在迭代中间进行结构性变化检测，如果容器发生了结构性变化，就会抛出 ConcurrentModificationException，所以不能在迭代中间直接调用容器类提供的 add、remove 方法，如需添加和删除，应调用迭代器的相关方法。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00018",
    "title": "请实现一个极简 LRU 算法容器？",
    "content": "无",
    "answer": "解析：</br></br>看起来是一道很难的题目，其实静下来你会发现想考察的其实就是 LRU 的原理和 LinkedHashMap 容器知识，当然，你要是厉害不依赖 LinkedHashMap 自己纯手写撸一个也不介意。 LinkedHashMap 支持插入顺序或者访问顺序，LRU 算法其实就要用到它访问顺序的特性，即对一个键执行 get、put 操作后其对应的键值对会移到链表末尾，所以最末尾的是最近访问的，最开始的最久没被访问的。 LRU 是一种流行的替换算法，它的全称是 Least Recently Used，最近最少使用，它的思路是最近刚被使用的很快再次被用的可能性最高，而最久没被访问的很快再次被用的可能性最低，所以被优先清理。 下面给出极简 LRU 缓存算法容器：</br></br>public class LRUCache<K, V> extends LinkedHashMap<K, V> {</br>    private int maxEntries;</br>    </br>\t//maxEntries 最大缓存个数</br>    public LRUCache(int maxEntries){</br>        super(16, 0.75f, true);</br>        this.maxEntries = maxEntries;</br>    }</br>    </br>\t//在添加元素到 LinkedHashMap 后会调用这个方法，传递的参数是最久没被访问的键值对，如果这个方法返回 true 则这个最久的键值对就会被删除，LinkedHashMap 的实现总是返回 false，所有容量没有限制。</br>    @Override</br>    protected boolean removeEldestEntry(Entry<K, V> eldest) {</br>        return size() > maxEntries;</br>    }</br>}   ",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00019",
    "title": "简单说说你对 Java 的 transient 关键字理解？",
    "content": "无",
    "answer": "解析：</br></br>我们都知道一个对象只要实现了 Serilizable 接口就可以被序列化了，java 的这种序列化模式使得我们可以不必关心具体序列化的过程，只要这个类实现了 Serilizable 接口则类的所有属性和方法都会自动序列化，而实际开发中我们常常会遇到这样的问题，这个类的有些属性需要序列化，而其他属性不需要被序列化，对于不要被序列化的属性就可以加上 transient 关键字。其主要的特性如下：</br></br>一旦变量被 transient 修饰就不再是对象持久化的一部分，该变量内容在序列化后无法获得访问；transient 关键字只能修饰变量而不能修饰方法和类（注意本地变量是不能被 transient 关键字修饰的）；变量如果是用户自定义类变量，则该类需要实现 Serializable 接口；被 transient 关键字修饰的变量不再能被序列化，一个静态变量不管是否被 transient 修饰均不能被序列化（一个静态变量不管是否被 transient 修饰均不能被序列化，反序列化后类中 static 型变量的值为当前 JVM 中对应 static 变量的值，这个值是 JVM 中的不是反序列化得出的）；在 Java 中对象的序列化可以通过实现两种接口来实现，若实现的是 Serializable 接口则所有的序列化将会自动进行，若实现的是 Externalizable 接口则没有任何东西可以自动序列化，需要在 writeExternal 方法中进行手工指定所要序列化的变量，这与是否被 transient 修饰无关。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00020",
    "title": "简单谈谈你所知道的 Java IO 流特性？",
    "content": "无",
    "answer": "解析：</br></br>java.io 包下面的流基本都是装饰器模式的实现，提供了各种类型流操作的便携性，常见的流分类如下：</br></br>以二进制字节方式读写的流（字节流没有编码的概念，转换字节需要考虑编码，不能按行处理，使用不太方便）主要有：</br></br>InputStream、OutputStream: 二进制字节读写抽象类型的基类。</br></br>FileInputStream、FileOutputStream: 输入输出目标是文件的流，构造支持 File 类型和 String 文件名类型及追加覆盖模式，以 byte 或 byte 数组读写文件，FileOutputStream 没有缓冲，没有重写flush，调用 flush 没有任何效果，数据只是传递给了操作系统，但操作系统什么时候保存到硬盘上是不一定的，按字节读取效率低。</br></br>ByteArrayInputStream、ByteArrayOutputStream: 输入输出目标是字节数组的流，数组的长度是根据数据内容动态扩展的，ByteArrayOutputStream 无缓存，同理 flush 无效。</br></br>DataInputStream、DataOutputStream: 按基本类型和字符串而非只是字节读写流装饰类，FilterInputStream、FilterOutputStream 装饰基类的子类，在写入时 DataOutputStream 会将这些类型的数据转换为其对应的二进制字节，必须按照字节读取，效率较低。</br></br>BufferedInputStream、BufferedOutputStream: 对输入输出流提供缓冲功能的装饰类，BufferedInputStream 内部有个字节数组作为缓冲区，读取时先从这个缓冲区读，缓冲区读完了再调用包装的流读，BufferedOutputStream 的构造方法也有两个，默认的缓冲区大小也是 8192，它的 flush 方法会将缓冲区的内容写到包装的流中。</br></br>PipedInputStream、PipedOutputStream：分别是管道输入输出流，作用是让多线程可以通过管道进行线程间的通讯，在使用管道通信时，必须将 PipedOutputStream 和 PipedInputStream 配套使用。</br></br>PrintStream：继承于 FilterOutputStream 来装饰其它输出流的流。提供了自动 flush 和字符集设置功能。</br></br>以文本字符方式读写的流（文本文件中编码非常重要）主要有：</br></br>Reader、Writer：字符流的抽象基类。</br></br>InputStreamReader、OutputStreamWriter：适配器类，输入是 InputStream，输出是 OutputStream，将字节流转换为字符流，一个重要的参数是编码类型，如果没有传则为系统默认编码。</br></br>FileReader、FileWriter：输入输出目标是文件的字符流，InputStreamReader、OutputStreamWriter 的子类，需要注意的是 FileReader、FileWriter 不能指定编码类型，只能使用默认编码，如果需要指定编码类型可以使用 InputStreamReader、OutputStreamWriter。</br></br>CharArrayReader、CharArrayWriter: 输入输出目标是 char 动态调整数组的字符流，类似 ByteArrayInputStream、ByteArrayOutputStream。</br></br>StringReader、StringWriter：输入输出目标是 String 的字符流，与 CharArrayReader、CharArrayWriter 类似。</br></br>BufferedReader、BufferedWriter：装饰类，对输入输出流提供缓冲以及按行读写功能，FileReader、FileWriter 是没有缓冲的、也不能按行读写，所以一般应该在它们的外面包上对应的缓冲类。</br></br>PrintWriter：装饰类，可直接指定文件名作为参数、可以指定编码类型、可以自动缓冲、可以自动将多种类型转换为字符串，在输出到文件时可以优先选择该类。</br></br>PipedReader、PipedWriter：分别是字符管道输入输出流，作用是让多线程可以通过管道进行线程间的通讯，在使用管道通信时，必须将 PipedReader、PipedWriter 配套使用。</br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00021",
    "title": "请简单谈谈你对 Java 的序列化与反序列化理解？",
    "content": "无",
    "answer": "解析：</br></br>序列化就是将对象转化为字节流，反序列化就是将字节流转化为对象，要让一个类支持序列化只要让这个类实现接口 java.io.Serializable 即可，Serializable 只是一个没有定义任何方法的标记接口，声明实现 Serializable 接口后保存读取对象就可以使用 ObjectOutputStream、ObjectInputStream 流了，ObjectOutputStream 是 OutputStream 的子类，但实现了 ObjectOutput 接口，ObjectOutput 是 DataOutput 的子接口，增加了一个 writeObject(Object obj) 方法将对象转化为字节写到流中，ObjectInputStream 是 InputStream 的子类，实现了ObjectInput 接口，ObjectInput 是 DataInput 的子接口，增加了一个 readObject() 方法从流中读取字节转为对象，序列化和反序列化的实质在于 ObjectOutputStream 的 writeObject 和 ObjectInputStream 的 readObject 方法实现，常见的 String、Date、Double、ArrayList、LinkedList、HashMap、TreeMap 等都默认实现了 Serializable。</br></br>有时候我们对象有些字段的值可能与内存位置（hashcode）、当前时间等有关，所以我们不想序列化他，因为反序列化后的值是没有意义的，或者有时候如果类中的字段表示的是类的实现细节而非逻辑信息则默认序列化也是不适合的，所以我们需要定制序列化。Java 提供的定制主要有 transient 关键字方式和实现 writeObject、readObject 方式及 Externalizable 接口 readResolve、writeReplace 方式，还可以将字段声明为 transient 后通过 writeObject、readObject 方法来自己保存该字段。</br></br>默认情况下 Java 会根据类中一系列信息自动生成一个版本号，在反序列化时如果类的定义发生了变化版本号就会变化，也就与反序列化流中的版本号不匹配导致会抛出异常，所以我们为了更好的控制和性能问题会自定义 serialVersionUID 版本号来避免类定义发生变化后反序列化版本号不匹配异常问题，如果版本号一样时流中有该字段而类定义中没有则该字段会被忽略，如果类定义中有而流中没有则该字段会被设为默认值，如果对于同名的字段类型变了则会抛出 InvalidClassException。</br></br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00022",
    "title": "Java 线程优先级是怎么定义的，Java 线程有几种状态？",
    "content": "无",
    "answer": "解析：</br></br>Java 线程的优先级定义为从 1 到 10 的等级，默认为 5，设置和获取线程优先级的方法是 setPriority(int newPriority) 和 getPriority()，Java 的这个优先级会被映射到操作系统中线程的优先级，不过由于操作系统各不相同，不一定都是 10 个优先级，所以 Java中 不同的优先级可能会被映射到操作系统中相同的优先级，同时优先级对操作系统而言更多的是一种建议和提示而非强制，所以我们不要过于依赖优先级。</br></br>Java Thread 可以通过 State getState() 来获取线程状态，Thread.State 枚举定义了 NEW、RUNNABLE、BLOCKED、WAITING、TIMED_WAITING、TERMINATED 六种线程状态，其实真正严格意义来说线程只有就绪、阻塞、运行三种状态，Java 线程之所以有六种状态其实是站在 Thread 对象实例的角度来看待的，具体解释如下：</br></br>NEW（新建），表示线程 Thread 刚被创建，还没调用 start 方法。</br></br>RUNNABLE（运行，实质对应就绪和运行状态），表示 Thread 线程正在 JVM 中运行，也就是说处于就绪和运行状态的线程在 Thread 中都表现为 RUNNABLE。</br></br>BLOCKED（阻塞，实质对应阻塞状态），表示等待监视锁可以重新进行同步代码块中执行，此线程需要获得某个锁才能继续执行，而这个锁目前被其他线程持有，所以进入了被动的等待状态，直到抢到了那个锁才会再次进入就绪状态。处于受阻塞状态的某一线程正在等待监视器锁，以便进入一个同步的块或方法，或者在调用 wait 之后再次进入同步的块或方法。</br></br>WAITING（等待，实质对应阻塞状态），表示此线程正处于无限期的主动等待中，直到有人唤醒它它才会再次进入就绪状态。某一线程因为调用下不带超时值的 wait、不带超时值的 join、LockSupport.park 会进入等待状态，处于等待状态的线程正等待另一个线程以执行特定操作，例如已经在某一对象上调用了 Object.wait() 的线程正等待另一个线程以便在该对象上调用 Object.notify() 或 Object.notifyAll()，或者已经调用了 Thread.join() 的线程正在等待指定线程终止。</br></br>TIMED_WAITING（有限等待，实质对应阻塞状态），表示此线程正处于有限期的主动等待中，要么有人唤醒它，要么等待够了一定时间之后才会再次进入就绪状态，譬如调用带有超时的 sleep、join、wait 方法可能导致线程处于等待状态。</br></br>TERMINATED（终止），表示线程执行完毕，已经退出。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00023",
    "title": "简单说说你对 Java synchronized 的理解？",
    "content": "无",
    "answer": "解析：</br></br>synchronized 关键字主要用来解决多线程共享内存的并发同步问题，可以用来修饰类的实例方法、静态方法、代码块；synchronized 实例方法实际保护的是同一个对象的方法调用，当为不同对象时多线程是可以同时访问同一个 synchronized 方法的；synchronized 静态方法和 synchronized 实例方法保护的是不同对象，不同的两个线程可以同时一个执行 synchronized 静态方法，另一个执行 synchronized 实例方法，因为 synchronized 静态方法保护的是 class 类对象，synchronized 实例方法保护的是 this 实例对象；synchronized 代码块同步的可以是任何对象，因为任何对象都有一个锁和等待队列。</br></br>synchronized 具备可重入性，对同一个线程在获得锁之后在调用其他需要同样锁的代码时可以直接调用，其可重入性是通过记录锁的持有线程和持有数量来实现的，调用 synchronized 代码时检查对象是否已经被锁，是则检查是否被当前线程锁定，是则计数加一，不是则加入等待队列，释放时计数减一直到为零释放锁。</br></br>synchronized 还具备内存可见性，除了实现原子操作避免竞态以外对于明显是原子操作的方法（譬如一个 boolean 状态变量 state 的 get 和 set 方法）也可以通过 synchronized 来保证并发的可见性，在释放锁时所有写入都会写回内存，而获得锁后都会从内存读取最新数据；不过对于已经是原子性的操作为了保证内存可见性而使用 synchronized 的成本会比较高，轻量级的选择应该是使用 volatile 修饰，一旦修饰 java 就会在操作对应变量时插入特殊指令保证可见性。</br></br>synchronized 是重量级锁，其语义底层是通过一个 monitor 监视器对象来完成，其实 wait、notify 等方法也依赖于 monitor 对象，所以这就是为什么只有在同步的块或者方法中才能调用 wait、notify 等方法，否则会抛出 IllegalMonitorStateException 异常的原因，监视器锁（monitor）的本质依赖于底层操作系统的互斥锁（Mutex Lock）实现，而操作系统实现线程之间的切换需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，所以这就是为什么 synchronized 效率低且重量级的原因（Java 1.6 进行了优化，但是相比其他锁机制还是略显偏重）。</br></br>synchronized 在发生异常时会自动释放线程占用的锁资源，Lock 需要在异常时主动释放，synchronized 在锁等待状态下无法响应中断而 Lock 可以。</br></br>还可以参考 JVM 官方文档：http://docs.oracle.com/javase/specs/jvms/se8/html/jvms-3.html#jvms-3.14",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0024",
    "title": "什么是死锁？请模拟写出一段 Java 死锁的核心代码？如何避免死锁？",
    "content": "无",
    "answer": "解析：</br></br>关于什么是死锁其实就是陷入互相等待谁都无法执行的一种状态，譬如有 A B 两个线程，A 持有 LockA 锁且在等待 LockB 锁，而 B 持有锁 LockB 且在等待 LockA 锁，LockA LockB 陷入互相等待导致谁都无法执行的一种现象。当发生死锁可以采用 jstack 命令进行分析，Android 上面可以采用 Android Device Monitor Thread 进行分析。</br></br>关于死锁的核心代码例子如下：</br></br>public class ThreadLoop {</br>    private static Object mLockA = new Object();</br>    private static Object mLockB = new Object();</br></br>    private static void startThreadA() {</br>        new Thread() {</br>            @Override</br>            public void run() {</br>                Log.i(\"YYYY\", \"startThreadA running!\");</br>                synchronized (mLockA) {</br>                    Log.i(\"YYYY\", \"startThreadA mLockA enter!\");</br>                    ThreadLoop.sleep(200);</br>                    synchronized (mLockB) {</br>                        Log.i(\"YYYY\", \"startThreadA mLockB enter!\");</br>                    }</br>                }</br>                Log.i(\"YYYY\", \"startThreadA over!\");</br>            }</br>        }.start();</br>    }</br></br>    private static void startThreadB() {</br>        new Thread() {</br>            @Override</br>            public void run() {</br>                Log.i(\"YYYY\", \"startThreadB running!\");</br>                synchronized (mLockB) {</br>                    Log.i(\"YYYY\", \"startThreadB mLockB enter!\");</br>                    ThreadLoop.sleep(200);</br>                    synchronized (mLockA) {</br>                        Log.i(\"YYYY\", \"startThreadB mLockA enter!\");</br>                    }</br>                }</br>                Log.i(\"YYYY\", \"startThreadB over!\");</br>            }</br>        }.start();</br>    }</br></br>    private static void sleep(long time) {</br>        try {</br>            Thread.sleep(time);</br>        } catch (InterruptedException e) {</br>            e.printStackTrace();</br>        }</br>    }</br></br>    public static void start() {</br>        startThreadA();</br>        startThreadB();</br>    }</br>}</br>运行结果可能如下：</br></br>startThreadA running!</br>startThreadA mLockA enter!</br>startThreadB running!</br>startThreadB mLockB enter!</br>//陷入死锁...</br>避免死锁其实主要有如下几个经验：</br></br>考虑加锁顺序：当多个线程需要相同的一些锁但每个线程又按照不同顺序加锁则很容易发生死锁（如上面死锁的例子），如果能确保所有的线程都是按照相同的顺序获得锁则发生死锁的情况就不存在了。</br></br>考虑加锁时限：可以在尝试获取锁的时候加一个超时时间，若一个线程没有在给定的时限内成功获得所有需要的锁则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试，这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "00025",
    "title": "下面程序有什么问题？该如何修改？",
    "content": "public class SyncCollection {\n    private static void putThread(final List<String> list) {\n        new Thread() {\n            @Override\n            public void run() {\n                for (int index=0; index<1000; index++) {\n                    list.add(\"data-\"+index);\n                }\n            }\n        }.start();\n    }\n\n    private static void loopThread(final List<String> list) {\n        new Thread() {\n            @Override\n            public void run() {\n                while (true) {\n                    for (String item : list) {\n                        Log.i(\"YYYY\", \"item is \"+item);\n                    }\n                }\n            }\n        }.start();\n    }\n\n    public static void run() {\n        final List<String> list = Collections.synchronizedList(new ArrayList<String>());\n        putThread(list);\n        loopThread(list);\n    }\n}",
    "answer": "解析：</br></br>该程序运行会在 loopThread 方法的 for 循环迭代器里面抛出 ConcurrentModificationException 异常，因为在遍历容器时容器结构发生了变化（add 操作），所以会抛出该异常，如果要避免这个问题需要在遍历容器时给整个容器对象加锁，如下：</br></br>......</br>while (true) {</br>        synchronized (list) {</br>            for (String item : list) {</br>                Log.i(\"YYYY\", \"item is \"+item);</br>            }</br>        }</br>    }</br>}</br>......</br>这样就保证了 for 循环迭代的同步性，之所以只给这个方法添加 synchronized (list) 是因为 list 对象其实就是 Collections.synchronizedList 返回的同步 List 里面 add 等操作用的锁对象，所以不用给上面的 putThread 方法再添加。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0026",
    "title": "简单谈谈 Java 并发协作的 wait、notify、notifyAll 等方法的特点和场景？",
    "content": "无",
    "answer": "解析：</br></br>首先并发协作的 wait、notify、notifyAll 等方法是定义在 java 的 Object 类中，而非 Thread，wait 有一个重载方法，参数 0 表示无限等待，更加重要的是在等待期间均可被中断抛出 InterruptedException（很重要），每个对象都有一把锁和等待队列，线程在进入 synchronized 时如果尝试获取锁失败就会把当前线程加入锁的等待队列，其实每个对象除过有用于锁的等待队列外还有一个条件队列，条件队列就是用来进行线程间的协作的，调用 wait 方法就会把当前线程放入这个条件队列并阻塞，然后等待其他线程通过 notify 或者 notifyAll 触发这个条件（自己无法触发）来执行，惟一的区别就是 notify 会从条件队列选择一个线程触发条件并且从队列移除而 notifyAll 会触发条件队列里所有等待的线程并从队列移除。</br></br>wait 和 notify、notifyAll 只能在 synchronized 函数或者对象中调用，被上锁的对象一般是多线程共享的对象，如果调用 wait 和 notify、notifyAll 方法时当前线程没有持有对象锁则会抛出 IllegalMonitorStateException 异常。切记代码执行到 synchronized 锁起来的 wait 方法时当前线程会释放对象锁，因为 wait 的具体实现过程是先把当前线程放入条件等待队列、释放对象锁、阻塞等待（线程状态变为 WAITING 或 TIMED_WATING），等待时间到了或者被其他线程 notify、notifyAll 以后从条件队列中移除然后要重新竞争对象锁，竞争到就变为 RUNNABLE 状态，否则该线程被加入对象锁队列变为 BLOCKED 状态。切记调用 notify、notifyAll 会把条件队列中等待的线程移除但是不会释放对象锁，只有在包含 notify、notifyAll 的 synchronized 方法或者代码块执行完毕才能轮到等待的线程执行。</br></br>除过我们要保证 wait 和 notify、notifyAll 应该在被 synchronized 的背景下和那个被多线程共享的对象上调用以外还要尽可能保证永远在条件循环而不是 if 语句中使用 wait，因为线程从 wait 调用中返回后不代表其等待的条件就一定成立，所以我们在使用 wait 时应该尽量使用如下模板：</br></br>// The standard idiom for calling the wait method in Java </br>synchronized (sharedObject) { </br>    while (condition) { </br>    sharedObject.wait(); </br>        // (Releases lock, and reacquires on wakeup) </br>    } </br>    // do action based upon condition e.g. take or put into queue </br>}</br>在条件循环里使用 wait 的目的是在线程被唤醒的前后都持续检查条件是否被满足，如果条件并未改变而 wait 被调用之前 notify 的唤醒通知就来了，那么这个线程并不能保证被唤醒且有可能会导致死锁问题（建立在全局项目超过两个线程以上）。譬如假设有两个生产者 A、B，一个消费者 C，在生产消费者模式中如果对生产者 A、B 不使用条件循环而简单 if 判断中调用 wait 就会出事，当空间满了后 A、B 都被 wait，当 C 取走一个数据后如果调用了 notifyAll 则 A、B 都将被唤醒，假设 A 被唤醒后往空间放入一个数据且空间满了，而此时 B 也会放置一个数据，所以发生空间炸裂错误。 （提示：如上也解答了并发的另一个面试题 ---- Java 多线程为什么使用 while 循环来调用 wait 方法？） （其实 Thread 的 join 方法实现也是条件循环，核心代码如下：while (isAlive()) {lock.wait(0);}）</br></br>并发协作其实在 java.util.concurrent 包下已经提供了很多不错且高效的封装实现类了，不过我们依然可以自己使用 wait 和 notify、notifyAll 来解决生产消费者场景、并发等待等场景问题。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0027",
    "title": "说说你知道的 Java 停止线程的方式及优劣点？",
    "content": "无",
    "answer": "解析：</br></br>关于停止 Java 线程的常见方式及优劣点主要如下：</br></br>[不推荐]使用 Thread 的 stop() 方式结束线程已经不推荐了，因为它是一种恶意的中断，一旦执行 stop 方法就会立即终止当前正在运行的线程，所以它无法保证线程逻辑是否完整（譬如线程中重要的资源清理等逻辑代码还没来得及执行就被 stop 掉了，这是非常危险的）；同时会破坏原子性操作，因为一般任何进行加锁的代码块都是为了保护数据的一致性，而调用 stop 后导致该线程所持有的所有锁被突然释放，这样就导致被保护的数据有可能呈现不一致性，其他线程在使用这些被破坏的数据时有可能导致一些很奇怪的应用程序错误。</br></br>[推荐]使用 Thread 的 interrupt() 方式中断线程是要看场景决定的，Java 的中断并不是 stop 一样强迫终止一个线程，而是一种给对应线程传递取消信号的协作机制，由对应线程决定如何及何时退出。每个线程都有一个中断标志位（Native 实现），线程的对象方法 isInterrupted() 方法就是返回该标志是否为 true；线程的静态方法 interrupted() 方法也是返回该标志是否为 true，但是它会清空标志位；调用 interrupt() 方法对线程的效果取决于线程的当前状态和在进行的 IO 操作，所以这种方式中断线程需要看场合决定。如果线程处于 RUNNABLE 状态且无 IO 操作则 interrupt() 方法只会设置线程的中断标志位而无其他任何作用，所以这种情况下我们需要在线程运行的合适位置检查中断标记来中断线程，譬如 while 循环条件为 !Thread.isInterrupted()；如果线程处于 WAITING、TIMED_WAITING 状态则 interrupt() 方法会使该线程抛出 InterruptedException 异常且在异常抛出后中断标志会被清空而不是设置，这也就是为什么我们使用 wait、join、sleep 方法时必须要处理受检查的 InterruptedException 异常原因，所以我们一般需要在捕获这种异常后进行线程的终止回收逻辑同时最好再调用一下 Thread.currentThread().interrupt() 设置下当前线程中断标志位；如果线程处于 BLOCKED 锁等待状态则 interrupt() 方法只会设置线程的中断标志位而无其他任何作用，所以 interrupt 无法让一个处于等待锁的线程真正中断，譬如当线程 A、B 共用 LockM 锁，A 如果在获取 LockM 锁后调用 B 的 interrupt() 后接着执行其他耗时操作后才释放 LockM 锁，而在 A 获得 LockM 锁的期间 B 刚好处于锁等待状态，这时即便 B 的锁代码块中显式调用了 !Thread.isInterrupted() 方法也不会中断，只能等到 B 获取锁后才可以中断；如果线程处于 NEW、TERMINATE 状态则 interrupt() 方法没有任何效果，中断标志都不会被设置，这自然是一种没有意义的操作；如果线程处于 IO 操作阻塞情况则 interrupted() 方法的效果取决于当前阻塞的 IO 类，如果类实现了 InterruptibleChannel 接口（一般都是 NIO 的通道操作有实现此接口）则可中断且使 IO 通道关闭且会收到 ClosedByInterruptException 异常且会设置中断状态，如果阻塞的 IO 类是 NIO 的 Selector 则也会被中断且设置标志，如果 IO 类操作是常见的 ServerSocket 的 accept、InputStream 的 read 等调用则只会设置线程的中断标志而不会中断。所以说如果不明白自己的线程在做什么就不要想当然的调用 interrupt()，因为不一定会终止线程，更多的是一种标志协作。</br></br>[推荐]自定义中断信号量方式，这种方式中断 RUNNABLE 状态的线程也是很常见的，使用 volatile 的原子性共享标记变量来告诉线程必须停止正在运行的任务。</br></br>[推荐]使用 java.util.concurrent 并发包下面提供的方法（很多实质还是 interrupt()），譬如 Future 的 boolean cancel(boolean mayInterruptIfRunning) 方法、ExecutorService 的 shutdown()、shutdownNow() 方法等。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0029",
    "title": "简单谈谈你对 Java 虚拟机内存模型 JMM 的认识和理解及并发中的原子性、可见性、有序性的理解？",
    "content": "无",
    "answer": "解析：</br></br>这是一个很泛很大且很有水准的面试题，也算是对并发基础原理实质的一个深度问题，想要在面试中简短的回答好不是特别容易，本解析也仅供参考，具体理解可自己查阅其他资料。</br></br>Java 内存模型主要目标是定义程序中变量（此处变量特指实例字段、静态字段等，但不包括局部变量和函数参数，因为这两种是线程私有无法共享）在虚拟机中存储到内存与从内存读取出来的规则细节，Java 内存模型规定所有变量都存储在主内存中，每条线程还有自己的工作内存，工作内存保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行而不能直接读写主内存中的变量，不同线程之间无法相互直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成。</br></br>Java 内存模型对主内存与工作内存之间的具体交互协议定义了八种操作，具体如下：</br></br>lock（锁定）：作用于主内存变量，把一个变量标识为一条线程独占状态。</br>unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</br>read（读取）：作用于主内存变量，把一个变量从主内存传输到线程的工作内存中，以便随后的 load 动作使用。</br>load（载入）：作用于工作内存变量，把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。</br>use（使用）：作用于工作内存变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量值的字节码指令时执行此操作。</br>assign（赋值）：作用于工作内存变量，把一个从执行引擎接收的值赋值给工作内存的变量，每当虚拟机遇到一个需要给变量进行赋值的字节码指令时执行此操作。</br>store（存储）：作用于工作内存变量，把工作内存中一个变量的值传递到主内存中，以便后续 write 操作。</br>write（写入）：作用于主内存变量，把 store 操作从工作内存中得到的值放入主内存变量中。</br>如果要把一个变量从主内存复制到工作内存就必须按顺序执行 read 和 load 操作，从工作内存同步回主内存就必须顺序执行 store 和 write 操作，但是 JVM 只要求了操作的顺序而没有要求上述操作必须保证连续性，所以实质执行中 read 和 load 间及 store 和 write 间是可以插入其他指令的。</br></br>Java 内存模型还会对指令进行重排序操作，在执行程序时为了提高性能编译器和处理器经常会对指令进行重排序操作，重排序主要分下面几类：</br></br>编译器优化重排序：编译器在不改变单线程程序语义的前提下可以重新安排语句的执行顺序。</br>指令级并行重排序：现代处理器采用了指令级并行技术来将多条指令重叠执行，如果不存在数据依赖性处理器可以改变语句对应机器指令的执行顺序。</br>内存系统重排序：由于处理器使用缓存和读写缓冲区使得加载和存储操作看上去可能是在乱序执行。</br>其实 Java JMM 内存模型是围绕并发编程中原子性、可见性、有序性三个特征来建立的，关于原子性、可见性、有序性的理解如下：</br></br>原子性：就是说一个操作不能被打断，要么执行完要么不执行，类似事务操作，Java 基本类型数据的访问大都是原子操作，long 和 double 类型是 64 位，在 32 位 JVM 中会将 64 位数据的读写操作分成两次 32 位来处理，所以 long 和 double 在 32 位 JVM 中是非原子操作，也就是说在并发访问时是线程非安全的，要想保证原子性就得对访问该数据的地方进行同步操作，譬如 synchronized 等。</br></br>可见性：就是说当一个线程对共享变量做了修改后其他线程可以立即感知到该共享变量的改变，从 Java 内存模型我们就能看出来多线程访问共享变量都要经过线程工作内存到主存的复制和主存到线程工作内存的复制操作，所以普通共享变量就无法保证可见性了；Java 提供了 volatile 修饰符来保证变量的可见性，每次使用 volatile 变量都会主动从主存中刷新，除此之外 synchronized、Lock、final 都可以保证变量的可见性。</br></br>有序性：就是说 Java 内存模型中的指令重排不会影响单线程的执行顺序，但是会影响多线程并发执行的正确性，所以在并发中我们必须要想办法保证并发代码的有序性；在 Java 里可以通过 volatile 关键字保证一定的有序性，还可以通过 synchronized、Lock 来保证有序性，因为 synchronized、Lock 保证了每一时刻只有一个线程执行同步代码相当于单线程执行，所以自然不会有有序性的问题；除此之外 Java 内存模型通过 happens-before 原则如果能推导出来两个操作的执行顺序就能先天保证有序性，否则无法保证，关于 happens-before 原则可以查阅相关资料。</br></br>所以说如果想让 Java 并发程序正确的执行必须保证原子性、有序性、可见性，只要三者中有任意一个不满足并发都无法正确执行。</br></br>（关于该问题答案还可参考：www.ifeve.com/java-memory-model-1/）",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0030",
    "title": "说说你对 Java 的 volatile 关键字的理解和使用场景举例？",
    "content": "无",
    "answer": "解析：</br></br>一旦一个并发共享变量（类的成员变量、静态成员变量）被 volatile 关键字修饰就具备了可见性（即一个线程修改了一个变量的值对于另一个线程来说是立即可见的）和有序性（即禁止进行指令重排序），实质是在生成的汇编代码中多了一个 lock 前缀指令。 譬如我们经常会使用标记法中断线程，如下：</br></br>boolean stop = false;</br>//线程1</br>while(!stop){</br>    //do some thread things...</br>}</br> </br>//线程2</br>stop = true;</br>这段代码其实大多数时候是可以中断线程1的，但是依然存在一定小概率无法中断线程1，因为每个线程都有自己的工作内存，当线程1运行时会对主存的 stop 变量拷贝一份放置到自己的工作内存使用，当线程2更改了 stop 变量的值后还未来得及写回主存中而接着做其他事情了，此时线程1可能无法立即感知到 stop 变量的改变而无法中断自己造成错误的逻辑，当我们对 stop 变量添加 volatile 修饰符后就不会存在上面的问题了，因为 volatile 会强制线程修改变量的改变立即回写到主存中，当线程2修改 stop 变量值时会导致线程1的工作内存中 stop 缓存失效进而主动去主存中重新读取 stop 值。</br></br>volatile 有序性的保证有两层含义，当程序执行到 volatile 变量的读或者写操作时在其前面的操作的更改肯定已经全部进行且结果已经对后面的操作可见，在其后面的操作肯定还没有进行，在进行指令优化时不能将对 volatile 变量访问的语句放在其后面执行，也不能把 volatile 变量后面的语句放到其前面执行。</br></br>volatile 常见的使用场景为多线程自定义条件标记变量中断和单例模式的 double check 等。</br></br>",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0031",
    "title": "什么是原子变量？为什么需要他们？Java 提供了哪些原子变量类型？",
    "content": "无",
    "answer": "解析：</br></br>原子变量就是原子操作，是在多线程环境下避免数据不一致必须的手段，譬如int++就不是一个原子操作，因为当一个线程读取它的值并加 1 时另外一个线程有可能会读到之前的值而引发错误，所以为了解决这个问题就必须保证增加操作是原子操作，在 JDK1.5 之前可以使用 synchronized 同步技术来做到原子操作（成本太高，需要获取释放锁，获取不到锁还要等待，还有线程的上下文切换操作），而在 JDK1.5 的 java.util.concurrent.atomic 包中 Java 提供了可以自动保证是原子操作且不需要使用 synchronized 同步的实现类。</br></br>synchronized 是一种阻塞式算法的悲观锁，但是原子变量的更新逻辑是非阻塞式乐观的，synchronized 得不到锁就会进入等待状态和有线程切换开销，原子变量更新冲突时会循环重试，不会阻塞和上下文切换开销。</br></br>java 提供的原子变量类型都在 java.util.concurrent.atomic 包下面，基本的有 AtomicBoolean（原子布尔类型）、AtomicInteger（原子Integer类型）、AtomicLong（原子Long类型）、AtomicReference（原子引用类型），针对基本的对应的数组类型有 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray，为了便于以原子方式更新对象中字段而增加的类型有 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater，AtomicReference 还有两个类似的类 AtomicMarkableReference、AtomicStampedReference，对于 char、short、float、double 类型如果我们需要可以转换（floatToIntBits）为 int 或者 long 来使用。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0032",
    "title": "简单谈谈你对 CAS 的认识和理解？",
    "content": "无",
    "answer": "解析：</br></br>CAS（compare and swap）实质就是比较交换策略，设计并发算法时常用到的一种技术，java.util.concurrent 包基本都建立在 CAS 之上，现代的处理器基本都支持 CAS，只是不同厂商实现不同而已；CAS 有内存值V、旧的预期值A、要修改的值B三个操作数，当且仅当预期值A和内存值V相同时才会将内存值修改为B并返回 true，否则什么也不做且返回 false。</br></br>CAS 是通过 Unsafe 类来实现的，Unsafe 提供了硬件级别的原子操作，关于 CAS 的方法主要是 native 的 compareAndSwapObject、compareAndSwapInt、compareAndSwapLong，其比较交换是一组原子操作，因为是硬件级别的操作，所以效率会高一些。</br></br>CAS 最常见和基础的使用地方在 java.util.concurrent.atomic 包下面，譬如 AtomicInteger 使用 CAS 的实质如下（基于JDK 1.8之前，1.8开始已经再次优化了，看不见阻塞的逻辑了）：</br></br>public class AtomicInteger extends Number implements java.io.Serializable {</br>    //Unsafe 是 CAS 的核心类</br>    private static final sun.misc.Unsafe unsafe = sun.misc.Unsafe.getUnsafe();</br>    //valueOffset 在 static 代码块中通过 Unsafe 获取 value 变量在内存中的偏移地址。</br>    //因为 Unsafe 是通过 valueOffset 内存偏移地址来获取数据的原始值的。</br>    private static final long valueOffset;</br>    //获取变量的偏移地址</br>    static {</br>        try {</br>            valueOffset = unsafe.objectFieldOffset</br>                (AtomicInteger.class.getDeclaredField(\"value\"));</br>        } catch (ReflectiveOperationException e) {</br>            throw new Error(e);</br>        }</br>    }</br>    //volatile修饰保证了 value 变量的可见性和有序性</br>    private volatile int value;</br></br>    public final int incrementAndGet() {</br>        //原子更新成功为止才返回</br>        for (;;) {</br>            int current = get();</br>            int next = current + 1;</br>            if (compareAndSet(current, next))</br>                return next;</br>            }</br>        }</br>    }</br>}</br>可以发现基于 CAS 可以实现乐观的非阻塞算法的 Java atomic 原子变量，除此之外还可以实现悲观阻塞式算法，譬如锁机制等。</br></br>CAS 策略算法其实有个致命的 ABA 问题，如果一个变量 V 初次读取时值为 A，并且在准备赋值时检查到仍然是 A，而这时候又在多线程的场景下我们是无法确认这段时间之内是否值被其他线程先修改为 B 接着改回了 A，所以 CAS 就会在这种场景下误认为变量从来没被修改过，也就是 ABA 问题了，这个问题一般是没啥影响的，如果程序逻辑需要处理 ABA 场景就可以使用 AtomicStampedReference，在修改值的同时传入一个唯一标记（譬如时间戳），只有值和标记都想等才进行修改，使用 AtomicMarkableReference 也可以，只不过标记是 boolean 类型。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0033",
    "title": "说说 synchronized 与 Lock 的区别及优劣点？你用过 Java Lock 的哪些实现类？",
    "content": "无",
    "answer": "解析：</br></br>关于 synchronized 与 Lock 的区别及优劣点主要如下： synchronized 是 Java 的一个内置特性关键字，而 Lock 是 Java 的一个接口类；synchronized 在发生异常时会自动释放线程占用的锁，而 Lock 在发生异常时（不发生也一样）需要主动在 finally 中调用 unLock() 去释放锁；Lock 可以让等待锁的线程响应中断，而 synchronized 无法响应中断，会一直等待下去；Lock 可以知道有没有成功获取到锁，而 synchronized 无法办到；Lock 可以提高多线程进行读操作的效率，而 synchronized 不可以；在性能上来说如果竞争资源不激烈则两者差距不大，如果竞争资源非常激烈（很多线程同时抢占）时 Lock 的性能远远好于 synchronized；不过要注意只能中断阻塞中的线程，一旦获取到锁进入运行状态就无法中断；Lock 和 synchronized 都可以保证保证内存可见性。</br></br>Lock 接口及其主要实现类都位于 java.util.concurrent.locks 包下，Lock 的主要方法如下：</br></br>//切记Lock不会主动释放锁</br>public interface Lock {</br>    //用来获取锁，如果锁已被其他线程获取则进行等待，等待过程无法中断。</br>    void lock();</br>    //用来获取锁，如果线程正在等待获取锁则这个线程能够响应中断，即可以中断线程的等待状态。</br>    void lockInterruptibly() throws InterruptedException;</br>    //用来尝试获取锁，如果获取成功则返回true，如果获取失败（即锁已被其他线程获取）则返回false，该方法会立即返回，在拿不到锁时也不会一直在那等待。</br>    boolean tryLock();</br>    //用来尝试获取锁，区别在于拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false，如果如果一开始拿到锁或者在等待期间内拿到了锁则返回true，等待期间可被中断。</br>    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;</br>    //用来释放锁，Lock 不会主动释放锁，需要手动调用此方法，一般写在 finally 语句中。</br>    void unlock();</br>    //创建一个 Lock 的 Condition。</br>    Condition newCondition();</br>}</br>ReentrantLock 和 synchronized 一样是一个可重入锁，也是唯一一个实现了 Lock 接口的类且提供了更多的方法的锁实现类，synchronized 是非公平锁，而 ReentrantLock 默认也是非公平锁，不过提供了构造参数实现公平锁，所谓的公平其实就是等待时间最长的线程优先获得锁，公平锁会影响性能。</br></br>ReadWriteLock 接口及其主要实现类都位于 java.util.concurrent.locks 包下，ReadWriteLock 的主要方法如下：</br></br>//将文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作。</br>public interface ReadWriteLock {</br>    //获取读锁</br>    Lock readLock();</br>    //获取写锁</br>    Lock writeLock();</br>}</br>ReentrantReadWriteLock 是 ReadWriteLock 接口的实现类，里面提供了很多丰富的方法，主要的 readLock() 和 writeLock() 方法用来获取读锁和写锁，效率比 synchronized 高很多，尤其在并发读文件情况下；不过要注意的是如果有一个线程已经占用了读锁则此时其他线程如果要申请写锁则申请写锁的线程会一直等待释放读锁，如果有一个线程已经占用了写锁则此时其他线程如果申请写锁或者读锁则申请的线程会一直等待释放写锁。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  },
  {
    "id": "0034",
    "title": "简单说说你所了解的 Java 锁分类和特点有哪些？",
    "content": "无",
    "answer": "解析：</br></br>其实对于 Java 锁的分类没有严格意义的规则，我们常说的分类一般都是依据锁的特性、锁的设计、锁的状态等进行归纳整理的，所以常见的分类如下：</br></br>公平锁、非公平锁：公平锁指多个线程按照申请锁的顺序来获取锁，非公平锁就是没有顺序完全随机，所以能会造成优先级反转或者饥饿现象；synchronized 就是非公平锁，ReentrantLock（使用 CAS 和 AQS 实现） 通过构造参数可以决定是非公平锁还是公平锁，默认构造是非公平锁；非公平锁的吞吐量性能比公平锁大好。</br></br>可重入锁：又名递归锁，指在同一个线程在外层方法获取锁的时候在进入内层方法会自动获取锁，synchronized 和 ReentrantLock 都是可重入锁，可重入锁可以在一定程度避免死锁。</br></br>独享锁、共享锁：独享锁是指该锁一次只能被一个线程持有，共享锁指该锁可以被多个线程持有；synchronized 和 ReentrantLock 都是独享锁，ReadWriteLock 的读锁是共享锁，写锁是独占锁；ReentrantLock 的独享锁和共享锁也是通过 AQS 来实现的。</br></br>互斥锁、读写锁：其实就是独享锁、共享锁的具体说法；互斥锁实质就是 ReentrantLock，读写锁实质就是 ReadWriteLock。</br></br>乐观锁、悲观锁：这个分类不是具体锁的分类，而是看待并发同步的角度；悲观锁认为对于同一个数据的并发操作一定是会发生修改的（哪怕实质没修改也认为会修改），因此对于同一个数据的并发操作悲观锁采取加锁的形式，因为悲观锁认为不加锁的操作一定有问题；乐观锁则认为对于同一个数据的并发操作是不会发生修改的，在更新数据的时候会采用不断的尝试更新，乐观锁认为不加锁的并发操作是没事的；由此可以看出悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升，悲观锁在 java 中很常见，乐观锁其实就是基于 CAS 的无锁编程，譬如 java 的原子类就是通过 CAS 自旋实现的。</br></br>分段锁：实质是一种锁的设计策略，不是具体的锁，对于 ConcurrentHashMap 而言其并发的实现就是通过分段锁的形式来实现高效并发操作；当要 put 元素时并不是对整个 hashmap 加锁，而是先通过 hashcode 知道它要放在哪个分段，然后对分段进行加锁，所以多线程 put 元素时只要放在的不是同一个分段就做到了真正的并行插入，但是统计 size 时就需要获取所有的分段锁才能统计；分段锁的设计是为了细化锁的粒度。</br></br>偏向锁、轻量级锁、重量级锁：这种分类是按照锁状态来归纳的，并且是针对 synchronized 的，java 1.6 为了减少获取锁和释放锁带来的性能问题而引入的一种状态，其状态会随着竞争情况逐渐升级，锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后无法降为偏向锁，这种升级无法降级的策略目的就是为了提高获得锁和释放锁的效率。</br></br>自旋锁：其实是相对于互斥锁的概念，互斥锁线程会进入 WAITING 状态和 RUNNABLE 状态的切换，涉及上下文切换、cpu 抢占等开销，自旋锁的线程一直是 RUNNABLE 状态的，一直在那循环检测锁标志位，机制不重复，但是自旋锁加锁全程消耗 cpu，起始开销虽然低于互斥锁，但随着持锁时间加锁开销是线性增长。</br></br>可中断锁：synchronized 是不可中断的，Lock 是可中断的，这里的可中断建立在阻塞等待中断，运行中是无法中断的。",
    "source": "https://github.com/TotemsCN/Base/blob/master/Java.md",
    "type": 1
  }
]